{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-03T17:46:35.161733Z","iopub.status.busy":"2023-03-03T17:46:35.160852Z","iopub.status.idle":"2023-03-03T17:46:35.183348Z","shell.execute_reply":"2023-03-03T17:46:35.17561Z","shell.execute_reply.started":"2023-03-03T17:46:35.161662Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name '_keras' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\UG-3-sem-2\\Computer_Vision-CV\\CV PROJECT\\Kaggle\\notebook8ae88d16bf.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UG-3-sem-2/Computer_Vision-CV/CV%20PROJECT/Kaggle/notebook8ae88d16bf.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UG-3-sem-2/Computer_Vision-CV/CV%20PROJECT/Kaggle/notebook8ae88d16bf.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/UG-3-sem-2/Computer_Vision-CV/CV%20PROJECT/Kaggle/notebook8ae88d16bf.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UG-3-sem-2/Computer_Vision-CV/CV%20PROJECT/Kaggle/notebook8ae88d16bf.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytesseract\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UG-3-sem-2/Computer_Vision-CV/CV%20PROJECT/Kaggle/notebook8ae88d16bf.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Kushg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:480\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    479\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m     _keras\u001b[39m.\u001b[39m_load()\n\u001b[0;32m    481\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    482\u001b[0m     \u001b[39mpass\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name '_keras' is not defined"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import pytesseract as pt\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import xml.etree.ElementTree as xet\n","\n","import keras\n","import keras.utils\n","from keras import utils as np_utils\n","\n","from glob import glob\n","from skimage import io\n","from shutil import copy\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import TensorBoard\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.applications import InceptionResNetV2\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:35.187268Z","iopub.status.busy":"2023-03-03T17:46:35.186835Z","iopub.status.idle":"2023-03-03T17:46:36.026857Z","shell.execute_reply":"2023-03-03T17:46:36.025797Z","shell.execute_reply.started":"2023-03-03T17:46:35.187227Z"},"trusted":true},"outputs":[],"source":["path = glob('/kaggle/input/indian-vehicle-dataset/google_images/*.xml')\n","labels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])\n","for filename in path:\n","\n","    info = xet.parse(filename)\n","    root = info.getroot()\n","    member_object = root.find('object')\n","    labels_info = member_object.find('bndbox')\n","    xmin = int(labels_info.find('xmin').text)\n","    xmax = int(labels_info.find('xmax').text)\n","    ymin = int(labels_info.find('ymin').text)\n","    ymax = int(labels_info.find('ymax').text)\n","\n","    labels_dict['filepath'].append(filename)\n","    labels_dict['xmin'].append(xmin)\n","    labels_dict['xmax'].append(xmax)\n","    labels_dict['ymin'].append(ymin)\n","    labels_dict['ymax'].append(ymax)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:36.028584Z","iopub.status.busy":"2023-03-03T17:46:36.028204Z","iopub.status.idle":"2023-03-03T17:46:36.047716Z","shell.execute_reply":"2023-03-03T17:46:36.046635Z","shell.execute_reply.started":"2023-03-03T17:46:36.028548Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame(labels_dict)\n","df.to_csv('labels.csv',index=False)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:36.050896Z","iopub.status.busy":"2023-03-03T17:46:36.050626Z","iopub.status.idle":"2023-03-03T17:46:36.060536Z","shell.execute_reply":"2023-03-03T17:46:36.058285Z","shell.execute_reply.started":"2023-03-03T17:46:36.050869Z"},"trusted":true},"outputs":[],"source":["filename = df['filepath'][0]\n","def getFilename(filename):\n","    filename_image = xet.parse(filename).getroot().find('filename').text\n","    filepath_image = os.path.join('/kaggle/input/indian-vehicle-dataset/google_images/',filename_image)\n","    return filepath_image\n","getFilename(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:36.064754Z","iopub.status.busy":"2023-03-03T17:46:36.064392Z","iopub.status.idle":"2023-03-03T17:46:36.35142Z","shell.execute_reply":"2023-03-03T17:46:36.350431Z","shell.execute_reply.started":"2023-03-03T17:46:36.064717Z"},"trusted":true},"outputs":[],"source":["image_path = list(df['filepath'].apply(getFilename))\n","image_path[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:36.353101Z","iopub.status.busy":"2023-03-03T17:46:36.352739Z","iopub.status.idle":"2023-03-03T17:46:36.437028Z","shell.execute_reply":"2023-03-03T17:46:36.43606Z","shell.execute_reply.started":"2023-03-03T17:46:36.353064Z"},"trusted":true},"outputs":[],"source":["#DATA VERIFICATION\n","file_path = image_path[87] #path of our image N2.jpeg\n","img = cv2.imread(file_path) #read the image\n","# xmin-1804/ymin-1734/xmax-2493/ymax-1882 \n","img = io.imread(file_path) #Read the image\n","fig = px.imshow(img)\n","fig.update_layout(width=600, height=500, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 8 - N2.jpeg with bounding box')\n","fig.add_shape(type='rect',x0=1804, x1=2493, y0=1734, y1=1882, xref='x', yref='y',line_color='cyan')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:36.438911Z","iopub.status.busy":"2023-03-03T17:46:36.438462Z","iopub.status.idle":"2023-03-03T17:46:42.644629Z","shell.execute_reply":"2023-03-03T17:46:42.643331Z","shell.execute_reply.started":"2023-03-03T17:46:36.438872Z"},"trusted":true},"outputs":[],"source":["#DATA PROCESSING\n","labels = df.iloc[:,1:].values\n","data = []\n","output = []\n","for ind in range(len(image_path)):\n","    image = image_path[ind]\n","    img_arr = cv2.imread(image)\n","    h,w,d = img_arr.shape\n","    # Prepprocesing\n","    load_image = load_img(image,target_size=(224,224))\n","    load_image_arr = img_to_array(load_image)\n","    norm_load_image_arr = load_image_arr/255.0 # Normalization\n","    # Normalization to labels\n","    xmin,xmax,ymin,ymax = labels[ind]\n","    nxmin,nxmax = xmin/w,xmax/w\n","    nymin,nymax = ymin/h,ymax/h\n","    label_norm = (nxmin,nxmax,nymin,nymax) # Normalized output\n","    # Append\n","    data.append(norm_load_image_arr)\n","    output.append(label_norm)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:42.646904Z","iopub.status.busy":"2023-03-03T17:46:42.646456Z","iopub.status.idle":"2023-03-03T17:46:42.735202Z","shell.execute_reply":"2023-03-03T17:46:42.733713Z","shell.execute_reply.started":"2023-03-03T17:46:42.646857Z"},"trusted":true},"outputs":[],"source":["# Convert data to array\n","X = np.array(data,dtype=np.float32)\n","y = np.array(output,dtype=np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:42.737683Z","iopub.status.busy":"2023-03-03T17:46:42.737187Z","iopub.status.idle":"2023-03-03T17:46:42.822118Z","shell.execute_reply":"2023-03-03T17:46:42.821083Z","shell.execute_reply.started":"2023-03-03T17:46:42.737636Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and testing set using sklearn.\n","x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=0)\n","x_train.shape,x_test.shape,y_train.shape,y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:42.824184Z","iopub.status.busy":"2023-03-03T17:46:42.823602Z","iopub.status.idle":"2023-03-03T17:46:43.178456Z","shell.execute_reply":"2023-03-03T17:46:43.177332Z","shell.execute_reply.started":"2023-03-03T17:46:42.824142Z"},"trusted":true},"outputs":[],"source":["# parsing\n","def parsing(path):\n","    parser = xet.parse(path).getroot()\n","    name = parser.find('filename').text\n","    filename = f'/kaggle/input/indian-vehicle-dataset/google_images/{name}'\n","\n","    # width and height\n","    parser_size = parser.find('size')\n","    width = int(parser_size.find('width').text)\n","    height = int(parser_size.find('height').text)\n","    \n","    return filename, width, height\n","df[['filename','width','height']] = df['filepath'].apply(parsing).apply(pd.Series)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:43.181192Z","iopub.status.busy":"2023-03-03T17:46:43.180551Z","iopub.status.idle":"2023-03-03T17:46:43.200539Z","shell.execute_reply":"2023-03-03T17:46:43.199411Z","shell.execute_reply.started":"2023-03-03T17:46:43.181152Z"},"trusted":true},"outputs":[],"source":["df['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\n","df['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n","\n","df['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\n","df['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:43.202915Z","iopub.status.busy":"2023-03-03T17:46:43.202193Z","iopub.status.idle":"2023-03-03T17:46:44.222452Z","shell.execute_reply":"2023-03-03T17:46:44.221096Z","shell.execute_reply.started":"2023-03-03T17:46:43.202872Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:44.225307Z","iopub.status.busy":"2023-03-03T17:46:44.224621Z","iopub.status.idle":"2023-03-03T17:46:54.330665Z","shell.execute_reply":"2023-03-03T17:46:54.329412Z","shell.execute_reply.started":"2023-03-03T17:46:44.225258Z"},"trusted":true},"outputs":[],"source":["!pip install -r ./yolov5/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:54.337114Z","iopub.status.busy":"2023-03-03T17:46:54.336791Z","iopub.status.idle":"2023-03-03T17:46:55.320129Z","shell.execute_reply":"2023-03-03T17:46:55.318796Z","shell.execute_reply.started":"2023-03-03T17:46:54.33708Z"},"trusted":true},"outputs":[],"source":["mkdir /kaggle/working/yolov5/data_images/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:55.322701Z","iopub.status.busy":"2023-03-03T17:46:55.322064Z","iopub.status.idle":"2023-03-03T17:46:56.314235Z","shell.execute_reply":"2023-03-03T17:46:56.312909Z","shell.execute_reply.started":"2023-03-03T17:46:55.322662Z"},"trusted":true},"outputs":[],"source":["mkdir /kaggle/working/yolov5/data_images/test/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:56.317461Z","iopub.status.busy":"2023-03-03T17:46:56.317024Z","iopub.status.idle":"2023-03-03T17:46:57.305771Z","shell.execute_reply":"2023-03-03T17:46:57.304451Z","shell.execute_reply.started":"2023-03-03T17:46:56.317411Z"},"trusted":true},"outputs":[],"source":["mkdir /kaggle/working/yolov5/data_images/train/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:57.309408Z","iopub.status.busy":"2023-03-03T17:46:57.308969Z","iopub.status.idle":"2023-03-03T17:46:57.315947Z","shell.execute_reply":"2023-03-03T17:46:57.314325Z","shell.execute_reply.started":"2023-03-03T17:46:57.309343Z"},"trusted":true},"outputs":[],"source":["### split the data into train and test\n","df_train = df.iloc[:200]\n","df_test = df.iloc[200:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:57.318522Z","iopub.status.busy":"2023-03-03T17:46:57.318052Z","iopub.status.idle":"2023-03-03T17:46:57.858096Z","shell.execute_reply":"2023-03-03T17:46:57.85701Z","shell.execute_reply.started":"2023-03-03T17:46:57.318466Z"},"trusted":true},"outputs":[],"source":["train_folder = './yolov5/data_images/train'\n","\n","values = df_train[['filename','center_x','center_y','bb_width','bb_height']].values\n","for fname, x,y, w, h in values:\n","    image_name = os.path.split(fname)[-1]\n","    txt_name = os.path.splitext(image_name)[0]\n","    \n","    dst_image_path = os.path.join(train_folder,image_name)\n","    dst_label_file = os.path.join(train_folder,txt_name+'.txt')\n","    \n","    # copy each image into the folder\n","    copy(fname,dst_image_path)\n","\n","    # generate .txt which has label info\n","    label_txt = f'0 {x} {y} {w} {h}'\n","    with open(dst_label_file,mode='w') as f:\n","        f.write(label_txt)\n","        \n","        f.close()\n","\n","test_folder = './yolov5/data_images/test'\n","\n","values = df_test[['filename','center_x','center_y','bb_width','bb_height']].values\n","for fname, x,y, w, h in values:\n","    image_name = os.path.split(fname)[-1]\n","    txt_name = os.path.splitext(image_name)[0]\n","    \n","    dst_image_path = os.path.join(test_folder,image_name)\n","    dst_label_file = os.path.join(test_folder,txt_name+'.txt')\n","    \n","    # copy each image into the folder\n","    copy(fname,dst_image_path)\n","\n","    # generate .txt which has label info\n","    label_txt = f'0 {x} {y} {w} {h}'\n","    with open(dst_label_file,mode='w') as f:\n","        f.write(label_txt)\n","        \n","        f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:57.862109Z","iopub.status.busy":"2023-03-03T17:46:57.861812Z","iopub.status.idle":"2023-03-03T17:46:57.87058Z","shell.execute_reply":"2023-03-03T17:46:57.869544Z","shell.execute_reply.started":"2023-03-03T17:46:57.862082Z"},"trusted":true},"outputs":[],"source":["import yaml\n","yaml_dict = {'train': 'data_images/train',   # path to the train folder\n","            'val': 'data_images/test', # path to the val folder\n","            'nc': 1,                             # number of classes\n","            'names': ['liscence_plate']}                # list of label names\n","\n","with open(r'./yolov5/data.yaml', 'w') as file:\n","    documents = yaml.dump(yaml_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:57.872483Z","iopub.status.busy":"2023-03-03T17:46:57.872126Z","iopub.status.idle":"2023-03-03T17:46:58.909843Z","shell.execute_reply":"2023-03-03T17:46:58.908147Z","shell.execute_reply.started":"2023-03-03T17:46:57.872446Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:46:58.912645Z","iopub.status.busy":"2023-03-03T17:46:58.912175Z","iopub.status.idle":"2023-03-03T17:47:09.063415Z","shell.execute_reply":"2023-03-03T17:47:09.062056Z","shell.execute_reply.started":"2023-03-03T17:46:58.912592Z"},"trusted":true},"outputs":[],"source":["!pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:47:09.066139Z","iopub.status.busy":"2023-03-03T17:47:09.065728Z","iopub.status.idle":"2023-03-03T17:47:18.762698Z","shell.execute_reply":"2023-03-03T17:47:18.761041Z","shell.execute_reply.started":"2023-03-03T17:47:09.066095Z"},"trusted":true},"outputs":[],"source":["!pip install GPUtil"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:47:18.766484Z","iopub.status.busy":"2023-03-03T17:47:18.765669Z","iopub.status.idle":"2023-03-03T17:47:19.03693Z","shell.execute_reply":"2023-03-03T17:47:19.035416Z","shell.execute_reply.started":"2023-03-03T17:47:18.766432Z"},"trusted":true},"outputs":[],"source":["\n","\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()\n","\n","free_gpu_cache()  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T17:47:19.039498Z","iopub.status.busy":"2023-03-03T17:47:19.038696Z","iopub.status.idle":"2023-03-03T18:06:30.798531Z","shell.execute_reply":"2023-03-03T18:06:30.797252Z","shell.execute_reply.started":"2023-03-03T17:47:19.039447Z"},"trusted":true},"outputs":[],"source":["!python ./yolov5/train.py --data ./yolov5/data.yaml --cfg ./yolov5/models/yolov5s.yaml --batch-size 8 --name Model --epochs 100"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:30.801074Z","iopub.status.busy":"2023-03-03T18:06:30.800653Z","iopub.status.idle":"2023-03-03T18:06:30.806534Z","shell.execute_reply":"2023-03-03T18:06:30.805293Z","shell.execute_reply.started":"2023-03-03T18:06:30.801027Z"},"trusted":true},"outputs":[],"source":["# import onnx\n","# from onnx import utils\n","\n","# model = onnx.load('model.onnx')\n","# model = utils.backward_compatible(model, target_version=11)\n","# onnx.save(model, 'model_v11.onnx')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:30.808314Z","iopub.status.busy":"2023-03-03T18:06:30.807939Z","iopub.status.idle":"2023-03-03T18:06:40.66865Z","shell.execute_reply":"2023-03-03T18:06:40.667387Z","shell.execute_reply.started":"2023-03-03T18:06:30.808277Z"},"trusted":true},"outputs":[],"source":["!python ./yolov5/export.py --weight ./yolov5/runs/train/Model/weights/best.pt --include torchscript onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:40.671388Z","iopub.status.busy":"2023-03-03T18:06:40.670951Z","iopub.status.idle":"2023-03-03T18:06:49.716649Z","shell.execute_reply":"2023-03-03T18:06:49.715324Z","shell.execute_reply.started":"2023-03-03T18:06:40.671322Z"},"trusted":true},"outputs":[],"source":["!python ./yolov5/export.py --weights ./yolov5/runs/train/Model/weights/best.pt --include torchscript onnx --opset 11\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:49.719453Z","iopub.status.busy":"2023-03-03T18:06:49.718648Z","iopub.status.idle":"2023-03-03T18:06:49.724989Z","shell.execute_reply":"2023-03-03T18:06:49.72377Z","shell.execute_reply.started":"2023-03-03T18:06:49.719404Z"},"trusted":true},"outputs":[],"source":["#predictions\n","\n","INPUT_WIDTH =  640\n","INPUT_HEIGHT = 640"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:49.727289Z","iopub.status.busy":"2023-03-03T18:06:49.726928Z","iopub.status.idle":"2023-03-03T18:06:49.953917Z","shell.execute_reply":"2023-03-03T18:06:49.952798Z","shell.execute_reply.started":"2023-03-03T18:06:49.727253Z"},"trusted":true},"outputs":[],"source":["# LOAD THE IMAGE\n","img = io.imread('/kaggle/input/car-number-plate-detection/Car_Number_Plate/1.png')\n","\n","fig = px.imshow(img)\n","fig.update_layout(width=700, height=400, margin=dict(l=10, r=10, b=10, t=10))\n","fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:49.95596Z","iopub.status.busy":"2023-03-03T18:06:49.955403Z","iopub.status.idle":"2023-03-03T18:06:50.002524Z","shell.execute_reply":"2023-03-03T18:06:50.001431Z","shell.execute_reply.started":"2023-03-03T18:06:49.955922Z"},"trusted":true},"outputs":[],"source":["# LOAD YOLO MODEL\n","net = cv2.dnn.readNetFromONNX('./yolov5/runs/train/Model/weights/best.onnx')\n","net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n","net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:50.004723Z","iopub.status.busy":"2023-03-03T18:06:50.004249Z","iopub.status.idle":"2023-03-03T18:06:50.021518Z","shell.execute_reply":"2023-03-03T18:06:50.020438Z","shell.execute_reply.started":"2023-03-03T18:06:50.004682Z"},"trusted":true},"outputs":[],"source":["def get_detections(img,net):\n","    # 1.CONVERT IMAGE TO YOLO FORMAT\n","    image = img.copy()\n","    row, col, d = image.shape\n","\n","    max_rc = max(row,col)\n","    input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n","    input_image[0:row,0:col] = image\n","\n","    # 2. GET PREDICTION FROM YOLO MODEL\n","    blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WIDTH,INPUT_HEIGHT),swapRB=True,crop=False)\n","    net.setInput(blob)\n","    preds = net.forward()\n","    detections = preds[0]\n","    \n","    return input_image, detections\n","\n","def non_maximum_supression(input_image,detections):\n","    \n","    # 3. FILTER DETECTIONS BASED ON CONFIDENCE AND PROBABILIY SCORE\n","    \n","    # center x, center y, w , h, conf, proba\n","    boxes = []\n","    confidences = []\n","\n","    image_w, image_h = input_image.shape[:2]\n","    x_factor = image_w/INPUT_WIDTH\n","    y_factor = image_h/INPUT_HEIGHT\n","\n","    for i in range(len(detections)):\n","        row = detections[i]\n","        confidence = row[4] # confidence of detecting license plate\n","        if confidence > 0.4:\n","            class_score = row[5] # probability score of license plate\n","            if class_score > 0.25:\n","                cx, cy , w, h = row[0:4]\n","\n","                left = int((cx - 0.5*w)*x_factor)\n","                top = int((cy-0.5*h)*y_factor)\n","                width = int(w*x_factor)\n","                height = int(h*y_factor)\n","                box = np.array([left,top,width,height])\n","\n","                confidences.append(confidence)\n","                boxes.append(box)\n","\n","    # 4.1 CLEAN\n","    boxes_np = np.array(boxes).tolist()\n","    confidences_np = np.array(confidences).tolist()\n","    \n","    # 4.2 NMS\n","    index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45)\n","    \n","    return boxes_np, confidences_np, index\n","\n","def drawings(image,boxes_np,confidences_np,index):\n","    # 5. Drawings\n","    texts = []\n","    for ind in index:\n","        x,y,w,h =  boxes_np[ind]\n","        bb_conf = confidences_np[ind]\n","        conf_text = 'plate: {:.0f}%'.format(bb_conf*100)\n","        license_text = extract_text(image,boxes_np[ind])\n","        texts.append(license_text)\n","\n","\n","        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)\n","        cv2.rectangle(image,(x,y-30),(x+w,y),(255,0,255),-1)\n","        cv2.rectangle(image,(x,y+h),(x+w,y+h+25),(0,0,0),-1)\n","\n","\n","        cv2.putText(image,conf_text,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),1)\n","        cv2.putText(image,license_text,(x,y+h+27),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),1)\n","\n","    return image, texts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:50.023625Z","iopub.status.busy":"2023-03-03T18:06:50.022862Z","iopub.status.idle":"2023-03-03T18:06:50.037168Z","shell.execute_reply":"2023-03-03T18:06:50.036151Z","shell.execute_reply.started":"2023-03-03T18:06:50.023587Z"},"trusted":true},"outputs":[],"source":["# predictions flow with return result\n","def yolo_predictions(img,net):\n","    # step-1: detections\n","    input_image, detections = get_detections(img,net)\n","    # step-2: NMS\n","    boxes_np, confidences_np, index = non_maximum_supression(input_image, detections)\n","    # step-3: Drawings\n","    result_img, texts = drawings(img,boxes_np,confidences_np,index)\n","    return result_img, texts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:50.039274Z","iopub.status.busy":"2023-03-03T18:06:50.038918Z","iopub.status.idle":"2023-03-03T18:06:55.659959Z","shell.execute_reply":"2023-03-03T18:06:55.6589Z","shell.execute_reply.started":"2023-03-03T18:06:50.039239Z"},"trusted":true},"outputs":[],"source":["import easyocr\n","\n","# initialize the EasyOCR reader\n","reader = easyocr.Reader(['en'])\n","\n","def extract_text(image,bbox):\n","    x,y,w,h = bbox\n","    roi = image[y:y+h, x:x+w]\n","    \n","    if 0 in roi.shape:\n","        return 'no number'\n","    \n","    else:\n","        # extract text using EasyOCR\n","        result = reader.readtext(roi)\n","        text = ' '.join([res[1] for res in result])\n","        text = text.strip()\n","        \n","        return text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:55.662043Z","iopub.status.busy":"2023-03-03T18:06:55.661682Z","iopub.status.idle":"2023-03-03T18:06:58.787344Z","shell.execute_reply":"2023-03-03T18:06:58.786359Z","shell.execute_reply.started":"2023-03-03T18:06:55.662005Z"},"trusted":true},"outputs":[],"source":["# test\n","from PIL import Image\n","img = Image.open('/kaggle/input/testing/TEST1.png')\n","\n","import numpy as np\n","img = np.array(img)\n","results, texts = yolo_predictions(img, net)\n","texts\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:58.789197Z","iopub.status.busy":"2023-03-03T18:06:58.788638Z","iopub.status.idle":"2023-03-03T18:06:59.033936Z","shell.execute_reply":"2023-03-03T18:06:59.031898Z","shell.execute_reply.started":"2023-03-03T18:06:58.789166Z"},"trusted":true},"outputs":[],"source":["fig = px.imshow(img)\n","fig.update_layout(width=700, height=400, margin=dict(l=10, r=10, b=10, t=10))\n","fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:06:59.036074Z","iopub.status.busy":"2023-03-03T18:06:59.03545Z","iopub.status.idle":"2023-03-03T18:07:01.204678Z","shell.execute_reply":"2023-03-03T18:07:01.203332Z","shell.execute_reply.started":"2023-03-03T18:06:59.036031Z"},"trusted":true},"outputs":[],"source":["!pip install libgtk2.0-dev"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T18:30:38.15763Z","iopub.status.busy":"2023-03-03T18:30:38.156573Z","iopub.status.idle":"2023-03-03T18:31:53.377674Z","shell.execute_reply":"2023-03-03T18:31:53.376126Z","shell.execute_reply.started":"2023-03-03T18:30:38.157588Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","\n","cap = cv2.VideoCapture('/kaggle/input/testing/anprTest.mp4')\n","text_results = []\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","\n","    if ret == False:\n","        print('Unable to read video')\n","        break\n","        \n","    for i in range(5):\n","            ret = cap.grab()\n","\n","    results, texts = yolo_predictions(frame,net)\n","    text_results.append(texts)\n","    print(texts)\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    plt.imshow(frame_rgb)\n","    plt.show()\n","#     if cv2.waitKey(30) == 27 :\n","#         break\n","#     if cv2.waitKey(1) == ord('q'):\n","#             break\n","\n","cv2.destroyAllWindows()\n","cap.release()\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
